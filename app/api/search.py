from fastapi import APIRouter, HTTPException, Query
from typing import List, Optional
from ..models.schemas import (
    SemanticSearchRequest,
    SemanticSearchResponse,
    RecipeSearchResult,
    IngredientSearchResult
)

# ğŸ¯ ìµœì¢… ì™„ì„±ëœ ì—„ê²©í•œ ì‹œë§¨í‹± ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì‚¬ìš©
print("ğŸ”„ ìµœì¢… ì™„ì„±ëœ ê²€ìƒ‰ ì„œë¹„ìŠ¤ ë¡œë”© ì‹œì‘...")

try:
    from app.services.final_strict_semantic_search_service import FinalStrictSemanticSearchService
    EnhancedSearchService = FinalStrictSemanticSearchService
    print("âœ… ìµœì¢… ì™„ì„±ëœ ì—„ê²©í•œ ì‹œë§¨í‹± ê²€ìƒ‰ ì„œë¹„ìŠ¤ ë¡œë“œ ì„±ê³µ!")
except ImportError as e:
    print(f"âŒ ìµœì¢… ì™„ì„± ì„œë¹„ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
    print("ğŸ”„ í´ë°±ìœ¼ë¡œ ì—„ê²©í•œ ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì‹œë„...")
    try:
        from app.services.strict_openai_semantic_search_service import StrictOpenAISemanticSearchService
        EnhancedSearchService = StrictOpenAISemanticSearchService
        print("âš ï¸ ì—„ê²©í•œ ê²€ìƒ‰ ì„œë¹„ìŠ¤ ë¡œë“œë¨ (ë°±ì—…)")
    except ImportError as e2:
        print(f"âŒ ì—„ê²©í•œ ì„œë¹„ìŠ¤ë„ ë¡œë“œ ì‹¤íŒ¨: {e2}")
        print("ğŸ”„ ìµœì¢… í´ë°±ìœ¼ë¡œ ê¸°ë³¸ OpenAI ì„œë¹„ìŠ¤ ì‹œë„...")
        try:
            from app.services.openai_semantic_search_service import OpenAISemanticSearchService
            EnhancedSearchService = OpenAISemanticSearchService
            print("âš ï¸ ê¸°ë³¸ OpenAI ì„œë¹„ìŠ¤ ë¡œë“œë¨ (ìµœì¢… í´ë°±)")
        except ImportError as e3:
            print(f"âŒ ëª¨ë“  ì„œë¹„ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e3}")
            print("ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ì„œë¹„ìŠ¤ë¡œ ìµœì¢… ì‹œë„...")
            from app.services.smart_hybrid_search_service import SmartHybridSearchService
            EnhancedSearchService = SmartHybridSearchService
            print("âš ï¸ í•˜ì´ë¸Œë¦¬ë“œ ì„œë¹„ìŠ¤ ë¡œë“œë¨ (ìµœì¢… ë°±ì—…)")

from app.clients.opensearch_client import opensearch_client
from app.clients.openai_client import openai_client
from app.utils.score_normalizer import ScoreNormalizer

router = APIRouter()

@router.post("/semantic", response_model=SemanticSearchResponse)
async def semantic_search(request: SemanticSearchRequest):
    """
    ğŸ¯ ìµœì¢… ì™„ì„±ëœ ì—„ê²©í•œ ì‹œë§¨í‹± ê²€ìƒ‰ API + ì˜¤íƒ€ êµì •
    
    âœ… ì£¼ìš” ê°œì„ ì‚¬í•­:
    - "ë¹„íŠ¸ì™€ í˜¸ë‘ ìš”ë¦¬" ë¬¸ì œ ì™„ì „ í•´ê²°
    - "í”¼ë§" â†’ "íŒŒí”„ë¦¬ì¹´" ë™ì˜ì–´ ë§¤ì¹­ ì§€ì›
    - ìŠ¤ë§ˆíŠ¸ í‚¤ì›Œë“œ ì¡°í•© ë¡œì§ ì ìš©
    - ì™„ë²½í•œ í…ìŠ¤íŠ¸ + ë²¡í„° í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
    - ê´€ë ¨ì„± ê²€ì¦ ê°•í™”
    - í•œê¸€ ì˜¤íƒ€ êµì • ('ã…‹ã…¡ë©´' â†’ 'ë¼ë©´')
    
    ğŸ” ê²€ìƒ‰ ë‹¨ê³„:
    0. ì˜¤íƒ€ êµì • (ìëª¨ ë¶„ë¦¬, í‚¤ë³´ë“œ ì˜¤íƒ€, AI êµì •)
    1. ì™„ë²½í•œ í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ì •í™•í•œ êµ¬ë¬¸ + ìŠ¤ë§ˆíŠ¸ ì¬ë£Œ ê²€ìƒ‰)
    2. ë²¡í„° ê²€ìƒ‰ (í•„ìš”ì‹œ)
    3. ìµœì¢… í†µí•© ë° ê´€ë ¨ì„± í•„í„°ë§
    """
    try:
        if not request.query or not request.query.strip():
            raise HTTPException(status_code=400, detail="ê²€ìƒ‰ì–´ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        query = request.query.strip()
        print(f"\nğŸ¯ ìµœì¢… ì™„ì„±ëœ ì‹œë§¨í‹± ê²€ìƒ‰ ìš”ì²­ (ì˜¤íƒ€ êµì • í¬í•¨): '{query}' (ì„œë¹„ìŠ¤: {EnhancedSearchService.__name__})")
        
        search_service = EnhancedSearchService()
        results = await search_service.semantic_search(
            query=query,
            search_type=request.search_type,
            limit=request.limit
        )
        
        print(f"ğŸ¯ ê²€ìƒ‰ ì™„ë£Œ: {len(results.recipes)}ê°œ ë ˆì‹œí”¼, {len(results.ingredients)}ê°œ ì¬ë£Œ")
        
        # ğŸ¯ í’ˆì§ˆ ê²€ì¦ ë¡œê·¸
        if results.recipes:
            print(f"\nğŸ“Š ìƒìœ„ ê²°ê³¼ í’ˆì§ˆ:")
            for i, recipe in enumerate(results.recipes[:3], 1):
                print(f"  {i}. {recipe.rcp_nm} = {recipe.score:.1f}ì  ({recipe.match_reason})")
        
        # ğŸš¨ ë¬¸ì œ ì¼€ì´ìŠ¤ ê°ì§€ (ê°œì„ ëœ ëª¨ë‹ˆí„°ë§)
        problematic_queries = ["í”¼ë§ ìš”ë¦¬", "ì¹˜í‚¨ ìš”ë¦¬", "íŒŒí”„ë¦¬ì¹´ ìš”ë¦¬"]
        if query.lower() in [q.lower() for q in problematic_queries]:
            main_ingredient = query.replace("ìš”ë¦¬", "").replace("ìŒì‹", "").strip()
            relevant_count = 0
            irrelevant_recipes = []
            
            for recipe in results.recipes:
                recipe_name = recipe.rcp_nm.lower()
                # ë” ì •êµí•œ ê´€ë ¨ì„± ê²€ì‚¬
                is_relevant = (
                    main_ingredient.lower() in recipe_name or
                    main_ingredient.lower() in str(recipe.ingredients).lower() or
                    (main_ingredient == "í”¼ë§" and "íŒŒí”„ë¦¬ì¹´" in recipe_name) or
                    (main_ingredient == "íŒŒí”„ë¦¬ì¹´" and "í”¼ë§" in recipe_name)
                )
                
                if is_relevant:
                    relevant_count += 1
                else:
                    # ëª…ë°±íˆ ë¬´ê´€í•œ ê²°ê³¼ë§Œ ê¸°ë¡
                    if not any(word in recipe_name for word in ["ë³¶ìŒ", "ì°Œê°œ", "êµ­", "íƒ•"]):
                        irrelevant_recipes.append(f"{recipe.rcp_nm} (ì ìˆ˜: {recipe.score:.1f})")
            
            if irrelevant_recipes:
                print(f"âš ï¸ ë¬´ê´€í•œ ê²°ê³¼ ê°ì§€: {len(irrelevant_recipes)}ê°œ")
                for irrelevant in irrelevant_recipes[:3]:
                    print(f"  - {irrelevant}")
            else:
                print(f"âœ… ëª¨ë“  ê²°ê³¼ê°€ ê´€ë ¨ì„± ìˆìŒ: {relevant_count}ê°œ ê´€ë ¨ ê²°ê³¼")
            
            print(f"ğŸ”§ ì‚¬ìš©ëœ ì„œë¹„ìŠ¤: {EnhancedSearchService.__name__}")
        
        return results
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        error_detail = f"ìµœì¢… ì™„ì„±ëœ ì‹œë§¨í‹± ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"
        print(f"Final semantic search error: {error_detail}")
        print(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=error_detail)

@router.get("/test")
async def test_search():
    """ê¸°ë³¸ì ì¸ OpenSearch ì—°ê²° í…ŒìŠ¤íŠ¸"""
    try:
        search_body = {"size": 5, "query": {"match_all": {}}}
        
        recipe_response = await opensearch_client.search(index="recipes", body=search_body)
        ingredient_response = await opensearch_client.search(index="ingredients", body=search_body)
        
        return {
            "status": "success",
            "recipe_count": len(recipe_response["hits"]["hits"]),
            "ingredient_count": len(ingredient_response["hits"]["hits"]),
            "sample_recipes": [hit["_source"] for hit in recipe_response["hits"]["hits"][:2]],
            "sample_ingredients": [hit["_source"] for hit in ingredient_response["hits"]["hits"][:2]],
            "active_search_service": EnhancedSearchService.__name__,
            "service_features": [
                "âœ… ìµœì¢… ì™„ì„±ëœ ì—„ê²©í•œ ê²€ìƒ‰",
                "âœ… ë™ì˜ì–´ ë§¤ì¹­ ì§€ì› (í”¼ë§â†”íŒŒí”„ë¦¬ì¹´)",
                "âœ… ìŠ¤ë§ˆíŠ¸ í‚¤ì›Œë“œ ì¡°í•©",
                "âœ… ì™„ë²½í•œ í…ìŠ¤íŠ¸ + ë²¡í„° í•˜ì´ë¸Œë¦¬ë“œ",
                "âœ… ë¬´ê´€í•œ ê²°ê³¼ ì œê±°"
            ]
        }
        
    except Exception as e:
        return {"status": "error", "error": str(e), "error_type": type(e).__name__}

@router.get("/debug/service-info")
async def debug_service_info():
    """í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì •ë³´"""
    return {
        "current_service": EnhancedSearchService.__name__,
        "service_module": EnhancedSearchService.__module__,
        "is_final_version": "Final" in EnhancedSearchService.__name__,
        "is_strict": "Strict" in EnhancedSearchService.__name__,
        "features": {
            "perfect_text_search": True,
            "smart_ingredient_search": True,
            "synonym_matching": True,
            "vector_search": True,
            "relevance_filtering": True,
            "smart_keyword_combination": True
        },
        "available_methods": [method for method in dir(EnhancedSearchService) if not method.startswith('_')],
        "supported_synonyms": {
            "í”¼ë§": ["íŒŒí”„ë¦¬ì¹´", "ë¹¨ê°„í”¼ë§", "ë…¸ë€í”¼ë§"],
            "íŒŒí”„ë¦¬ì¹´": ["í”¼ë§", "ë¹¨ê°„íŒŒí”„ë¦¬ì¹´", "ë…¸ë€íŒŒí”„ë¦¬ì¹´"],
            "ì–‘ë°°ì¶”": ["ë°°ì¶”", "ìºë¹„ì§€"],
            "ëŒ€íŒŒ": ["íŒŒ", "ìª½íŒŒ"]
        }
    }

@router.get("/recipes")
async def search_recipes(
    query: str = Query(..., description="ê²€ìƒ‰í•  ë ˆì‹œí”¼ëª… ë˜ëŠ” í‚¤ì›Œë“œ"),
    limit: int = Query(10, ge=1, le=50, description="ë°˜í™˜í•  ê²°ê³¼ ìˆ˜")
):
    """ë ˆì‹œí”¼ í…ìŠ¤íŠ¸ ê²€ìƒ‰ API - ê¸°ë³¸ í…ìŠ¤íŠ¸ ê²€ìƒ‰"""
    try:
        search_body = {
            "query": {
                "bool": {
                    "should": [
                        {"match": {"name": {"query": query, "boost": 3}}},
                        {"match": {"ingredients": {"query": query, "boost": 2}}},
                        {"match": {"category": {"query": query, "boost": 1}}},
                        {"match": {"cooking_method": {"query": query, "boost": 1}}}
                    ],
                    "minimum_should_match": 1
                }
            },
            "size": limit
        }
        
        response = await opensearch_client.search(index="recipes", body=search_body)
        
        results = []
        for hit in response["hits"]["hits"]:
            source = hit["_source"]
            normalized_score = ScoreNormalizer.normalize_text_score(hit["_score"])
            
            results.append({
                "rcp_seq": str(source.get("recipe_id", "")),
                "name": source.get("name", ""),
                "category": source.get("category", ""),
                "cooking_method": source.get("cooking_method", ""),
                "ingredients": str(source.get("ingredients", "")),
                "score": normalized_score
            })
        
        return {"query": query, "results": results, "total": len(results)}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë ˆì‹œí”¼ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")

@router.get("/ingredients")
async def search_ingredients(
    query: str = Query(..., description="ê²€ìƒ‰í•  ì¬ë£Œëª…"),
    limit: int = Query(10, ge=1, le=50, description="ë°˜í™˜í•  ê²°ê³¼ ìˆ˜")
):
    """ì¬ë£Œ í…ìŠ¤íŠ¸ ê²€ìƒ‰ API - ë™ì˜ì–´ í¬í•¨ ê²€ìƒ‰"""
    try:
        # ë™ì˜ì–´ ë§¤í•‘
        synonyms = {
            "í”¼ë§": ["íŒŒí”„ë¦¬ì¹´", "ë¹¨ê°„í”¼ë§", "ë…¸ë€í”¼ë§"],
            "íŒŒí”„ë¦¬ì¹´": ["í”¼ë§", "ë¹¨ê°„íŒŒí”„ë¦¬ì¹´", "ë…¸ë€íŒŒí”„ë¦¬ì¹´"],
            "ì–‘ë°°ì¶”": ["ë°°ì¶”", "ìºë¹„ì§€"],
            "ë°°ì¶”": ["ì–‘ë°°ì¶”", "ìºë¹„ì§€"],
            "ëŒ€íŒŒ": ["íŒŒ", "ìª½íŒŒ"],
            "íŒŒ": ["ëŒ€íŒŒ", "ìª½íŒŒ"]
        }
        
        # ê²€ìƒ‰í•  í‚¤ì›Œë“œë“¤
        search_terms = [query]
        if query in synonyms:
            search_terms.extend(synonyms[query])
        
        all_results = {}
        for term in search_terms:
            search_body = {
                "query": {
                    "bool": {
                        "should": [
                            {"match": {"name": {"query": term, "boost": 3}}},
                            {"match": {"category": {"query": term, "boost": 1}}},
                            {"match": {"aliases": {"query": term, "boost": 2}}}
                        ],
                        "minimum_should_match": 1
                    }
                },
                "size": limit
            }
            
            response = await opensearch_client.search(index="ingredients", body=search_body)
            
            for hit in response["hits"]["hits"]:
                source = hit["_source"]
                ingredient_id = source.get("ingredient_id", 0)
                if ingredient_id and ingredient_id not in all_results:
                    all_results[ingredient_id] = hit
        
        results = []
        for hit in all_results.values():
            source = hit["_source"]
            normalized_score = ScoreNormalizer.normalize_text_score(hit["_score"])
            
            results.append({
                "ingredient_id": source.get("ingredient_id", 0),
                "name": source.get("name", ""),
                "category": source.get("category", ""),
                "score": normalized_score
            })
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        results.sort(key=lambda x: x["score"], reverse=True)
        
        return {"query": query, "results": results[:limit], "total": len(results[:limit]), "search_terms": search_terms}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì¬ë£Œ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")

@router.post("/vector")
async def vector_search(request: dict):
    """ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ API - Java ë°±ì—”ë“œ ì™„ì „ í˜¸í™˜"""
    try:
        query = request.get("query", "")
        limit = request.get("limit", 10)
        
        print(f"ë²¡í„° ê²€ìƒ‰ ìš”ì²­: query='{query}', limit={limit}")
        
        if not query:
            return {"query": "", "results": [], "total": 0, "searchMethod": "no_query"}
        
        try:
            print("OpenAI ì„ë² ë”© ìƒì„± ì¤‘...")
            query_embedding = await openai_client.get_embedding(query)
            print(f"ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(query_embedding)}ì°¨ì›")
        except Exception as e:
            print(f"OpenAI API ì˜¤ë¥˜: {e}")
            return {"query": query, "results": [], "total": 0, "searchMethod": "openai_error"}
        
        try:
            print("ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
            vector_results = await opensearch_client.search_recipes_by_ingredients([query_embedding], limit)
            print(f"ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: {len(vector_results)}ê°œ ê²°ê³¼")
            
            if not vector_results:
                print("ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return {"query": query, "results": [], "total": 0, "searchMethod": "no_results"}
            
            results = []
            for i, result in enumerate(vector_results):
                try:
                    print(f"ê²°ê³¼ {i+1} ì²˜ë¦¬ ì¤‘: {result.get('name', 'N/A')}")
                    
                    recipe_id = str(result.get("recipe_id", ""))
                    name = str(result.get("name", ""))
                    category = str(result.get("category", ""))
                    cooking_method = str(result.get("cooking_method", ""))
                    score = float(result.get("score", 0.0))
                    ingredients_text = str(result.get("ingredients", ""))
                    image = str(result.get("image", ""))
                    thumbnail = str(result.get("thumbnail", ""))
                    
                    ingredient_dtos = []
                    if ingredients_text and ingredients_text.strip():
                        try:
                            ingredient_names = [name.strip() for name in ingredients_text.split(",")]
                            for idx, ingredient_name in enumerate(ingredient_names[:10]):
                                if ingredient_name:
                                    ingredient_dtos.append({
                                        "ingredient_id": int(idx + 1),
                                        "name": str(ingredient_name).strip(),
                                        "is_main_ingredient": bool(idx < 3)
                                    })
                        except Exception as ingredient_error:
                            print(f"ì¬ë£Œ íŒŒì‹± ì˜¤ë¥˜: {ingredient_error}")
                            ingredient_dtos = []
                    
                    normalized_score = ScoreNormalizer.normalize_vector_score(score)
                    
                    recipe_dto = {
                        "rcp_seq": recipe_id,
                        "rcp_nm": name,
                        "rcp_category": category,
                        "rcp_way2": cooking_method,
                        "image": image,
                        "thumbnail": thumbnail,
                        "score": normalized_score,
                        "match_reason": "ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰",
                        "ingredients": ingredient_dtos
                    }
                    
                    results.append(recipe_dto)
                    print(f"ê²°ê³¼ {i+1} ë³€í™˜ ì™„ë£Œ")
                    
                except Exception as result_error:
                    print(f"ê²°ê³¼ {i+1} ì²˜ë¦¬ ì˜¤ë¥˜: {result_error}")
                    continue
            
            final_response = {
                "query": query,
                "results": results,
                "total": len(results),
                "searchMethod": "script_score"
            }
            
            print(f"ìµœì¢… ì‘ë‹µ: {len(results)}ê°œ ê²°ê³¼")
            return final_response
            
        except Exception as search_error:
            print(f"ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {search_error}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return {"query": query, "results": [], "total": 0, "searchMethod": "search_error"}
        
    except Exception as e:
        print(f"ë²¡í„° ê²€ìƒ‰ ì „ì²´ ì˜¤ë¥˜: {e}")
        import traceback
        print(f"ì „ì²´ ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
        return {"query": request.get("query", ""), "results": [], "total": 0, "searchMethod": "total_error"}

@router.get("/test-typo-correction")
async def test_typo_correction():
    """í•œê¸€ ì˜¤íƒ€ êµì • ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    test_cases = [
        "ã„¹ã…ë©´",      # ë¼ë©´
        "ã„±ã…£ì§€",      # ê¹€ì¹˜  
        "ã…ã…£ë§",      # í”¼ë§
        "ã…ã…í”„ë¦¬ì¹´",   # íŒŒí”„ë¦¬ì¹´
        "ã…Šã…“ê¸°",      # ì¹˜í‚¨
        "ã…‡ã…ì¹¨ ì‹ì‚¬", # ì•„ì¹¨ ì‹ì‚¬
        "ã…ã…ë¼íƒ•ë©´",   # ë§ˆë¼íƒ•ë©´
        "ë¼ë©´",       # ì´ë¯¸ ì˜¬ë°”ë¦„
        "normal text"  # ì˜ì–´
    ]
    
    try:
        from app.utils.korean_typo_corrector import KoreanTypoCorrector
        corrector = KoreanTypoCorrector()
        
        results = {}
        for test_case in test_cases:
            try:
                corrected = await corrector.correct_typo(test_case)
                suggestions = corrector.get_typo_suggestions(test_case)
                
                results[test_case] = {
                    "original": test_case,
                    "corrected": corrected,
                    "suggestions": suggestions,
                    "changed": corrected != test_case
                }
            except Exception as e:
                results[test_case] = {
                    "error": str(e),
                    "original": test_case
                }
        
        return {
            "status": "success",
            "typo_correction_results": results,
            "summary": {
                "total_tests": len(test_cases),
                "successful_corrections": len([r for r in results.values() if r.get("changed", False)]),
                "errors": len([r for r in results.values() if "error" in r])
            }
        }
        
    except Exception as e:
        return {
            "status": "error", 
            "error": str(e),
            "message": "ì˜¤íƒ€ êµì • ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨"
        }

@router.get("/test-semantic-queries")
async def test_semantic_queries():
    """ì£¼ìš” ì‹œë§¨í‹± ê²€ìƒ‰ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸"""
    test_queries = [
        "í”¼ë§ ìš”ë¦¬",
        "íŒŒí”„ë¦¬ì¹´ ìš”ë¦¬", 
        "ì¹˜í‚¨ ìš”ë¦¬",
        "íŒŒí”„ë¦¬ì¹´",
        "í”¼ë§"
    ]
    
    results = {}
    search_service = EnhancedSearchService()
    
    for query in test_queries:
        try:
            print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{query}'")
            search_result = await search_service.semantic_search(query=query, limit=5)
            
            results[query] = {
                "recipe_count": len(search_result.recipes),
                "top_recipes": [
                    {
                        "name": recipe.rcp_nm,
                        "score": recipe.score,
                        "match_reason": recipe.match_reason
                    }
                    for recipe in search_result.recipes[:3]
                ],
                "processing_time": search_result.processing_time
            }
            
        except Exception as e:
            results[query] = {"error": str(e)}
    
    return {
        "service_used": EnhancedSearchService.__name__,
        "test_results": results,
        "summary": {
            "total_queries": len(test_queries),
            "successful_queries": len([r for r in results.values() if "error" not in r])
        }
    }

# ê¸°ì¡´ ë””ë²„ê·¸ ì—”ë“œí¬ì¸íŠ¸ë“¤ ìœ ì§€
@router.get("/debug-image-fields")
async def debug_image_fields():
    """ì´ë¯¸ì§€ í•„ë“œ ë””ë²„ê¹…"""
    try:
        sample_response = await opensearch_client.search(
            index="recipes",
            body={"size": 3, "query": {"match_all": {}}, "_source": ["recipe_id", "name", "image", "thumbnail", "category"]}
        )
        
        results = []
        for hit in sample_response["hits"]["hits"]:
            source = hit["_source"]
            results.append({
                "recipe_id": source.get("recipe_id"),
                "name": source.get("name"),
                "image": source.get("image"),
                "thumbnail": source.get("thumbnail"),
                "has_image": bool(source.get("image")),
                "has_thumbnail": bool(source.get("thumbnail"))
            })
        
        return {
            "status": "success",
            "sample_count": len(results),
            "samples": results,
            "fields_in_index": list(sample_response["hits"]["hits"][0]["_source"].keys()) if results else []
        }
        
    except Exception as e:
        return {"status": "error", "error": str(e)}

@router.get("/debug/{index_name}")
async def debug_index(index_name: str):
    """íŠ¹ì • ì¸ë±ìŠ¤ ë””ë²„ê·¸ ì •ë³´ ì¡°íšŒ"""
    try:
        exists = opensearch_client.client.indices.exists(index=index_name)
        if not exists:
            return {"error": f"ì¸ë±ìŠ¤ '{index_name}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"}
        
        mapping = opensearch_client.client.indices.get_mapping(index=index_name)
        count = opensearch_client.client.count(index=index_name)
        sample = opensearch_client.client.search(index=index_name, body={"size": 2, "query": {"match_all": {}}})
        
        return {
            "index": index_name,
            "exists": exists,
            "document_count": count["count"],
            "fields": list(mapping[index_name]["mappings"]["properties"].keys()),
            "sample_documents": [hit["_source"] for hit in sample["hits"]["hits"]]
        }
        
    except Exception as e:
        return {"error": str(e)}

@router.get("/test-vector")
async def test_vector_search():
    """ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    try:
        sample_ingredient = opensearch_client.client.search(
            index="ingredients",
            body={"size": 1, "query": {"exists": {"field": "embedding"}}, "_source": ["ingredient_id", "name", "embedding"]}
        )
        
        if not sample_ingredient["hits"]["hits"]:
            return {"error": "ì„ë² ë”©ì´ ìˆëŠ” ì¬ë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        ingredient_doc = sample_ingredient["hits"]["hits"][0]["_source"]
        ingredient_name = ingredient_doc.get('name', 'N/A')
        ingredient_embedding = ingredient_doc.get('embedding', [])
        
        vector_results = await opensearch_client.search_recipes_by_ingredients([ingredient_embedding], limit=5)
        ingredient_results = await opensearch_client.vector_search_ingredients(ingredient_embedding, limit=5)
        
        return {
            "test_ingredient": ingredient_name,
            "embedding_dimension": len(ingredient_embedding),
            "recipe_results": len(vector_results),
            "ingredient_results": len(ingredient_results),
            "sample_recipes": [r.get("name", "") for r in vector_results[:3]],
            "sample_ingredients": [r.get("name", "") for r in ingredient_results[:3]],
            "status": "success"
        }
        
    except Exception as e:
        return {"error": str(e), "status": "failed"}

@router.get("/test-java-format")
async def test_java_format():
    """Java ë°±ì—”ë“œ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸"""
    try:
        search_body = {"query": {"match": {"name": "ê¹€ì¹˜ì°Œê°œ"}}, "size": 3}
        response = await opensearch_client.search(index="recipes", body=search_body)
        
        results = []
        for hit in response["hits"]["hits"]:
            source = hit["_source"]
            normalized_score = ScoreNormalizer.normalize_text_score(hit["_score"])
            
            results.append({
                "recipe_id": str(source.get("recipe_id", "")),
                "name": source.get("name", ""),
                "category": source.get("category", ""),
                "ingredients": str(source.get("ingredients", "")),
                "score": normalized_score,
                "cooking_method": source.get("cooking_method", "")
            })
        
        return {"query": "ê¹€ì¹˜ì°Œê°œ", "results": results, "total": len(results), "search_method": "text_for_java_test"}
        
    except Exception as e:
        return {"error": str(e)}